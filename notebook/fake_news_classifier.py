# -*- coding: utf-8 -*-
"""fake-news-classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lGbP-uFjh-Z9HAC8PiY91T2teYKQRCFE

## IMPORTS
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from xgboost import XGBClassifier
import torch
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from datasets import Dataset
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

fake_df = pd.read_csv('/content/Fake.csv')
true_df = pd.read_csv('/content/True.csv')

"""## FEATURE ENGINEERING"""

print("Fake Dataset Columns:", fake_df.columns.tolist())
print("True Dataset Columns:", true_df.columns.tolist())

fake_df.head()

fake_df.tail()

true_df.head()

true_df.tail()

fake_df['label'] = 0
true_df['label'] = 1

data_df = pd.concat([fake_df, true_df], ignore_index=True)

data_df.shape

data_df.info()

print("\nüîç Missing Values:\n", data_df.isnull().sum())

print("\n Duplicate Rows:", data_df.duplicated().sum())

data_df = data_df.drop_duplicates().reset_index(drop=True)

data_df.shape

data_df.duplicated().sum()

"""## EDA"""

sns.set(style='whitegrid')
plt.rcParams['figure.figsize'] = (10, 5)

sns.countplot(x='label', data=data_df, palette='Set2')
plt.xticks([0, 1], ['Fake', 'Real'])
plt.title('Distribution of Fake vs Real News')
plt.xlabel('News Type')
plt.ylabel('Count')
plt.show()

data_df['title_length'] = data_df['title'].apply(len)
data_df['word_count'] = data_df['title'].apply(lambda x: len(str(x).split()))

sns.histplot(data_df['title_length'], bins=50, kde=True, color='skyblue')
plt.title('Title Length Distribution (Character Count)')
plt.xlabel('Title Length')
plt.ylabel('Frequency')
plt.show()

sns.histplot(data_df['word_count'], bins=30, kde=True, color='coral')
plt.title('Title Word Count Distribution')
plt.xlabel('Number of Words')
plt.ylabel('Frequency')
plt.show()

print("Average Title Length (Fake):", data_df[data_df['label'] == 0]['title_length'].mean())
print("Average Title Length (Real):", data_df[data_df['label'] == 1]['title_length'].mean())

print("Average Word Count (Fake):", data_df[data_df['label'] == 0]['word_count'].mean())
print("Average Word Count (Real):", data_df[data_df['label'] == 1]['word_count'].mean())

if 'subject' in data_df.columns:
    sns.countplot(y='subject', data=data_df, order=data_df['subject'].value_counts().index, palette='pastel')
    plt.title('Subject Distribution in News')
    plt.xlabel('Count')
    plt.ylabel('Subject')
    plt.show()

data_df['date'] = pd.to_datetime(data_df['date'], errors='coerce')
data_df['year'] = data_df['date'].dt.year

sns.countplot(x='year', data=data_df, palette='coolwarm')
plt.title('Articles Published per Year')
plt.xlabel('Year')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

"""## MODELS"""

custom_stopwords = set([
    'a', 'an', 'the', 'and', 'or', 'is', 'of', 'in', 'to', 'for', 'with', 'on',
    'by', 'at', 'from', 'that', 'this', 'it', 'be', 'as', 'are', 'was', 'were',
    'has', 'have', 'had', 'but', 'not', 'they', 'he', 'she', 'we', 'you', 'i'
])

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^a-z\s]', '', text)
    words = text.split()
    words = [word for word in words if word not in custom_stopwords]
    return ' '.join(words)

data_df['clean_title'] = data_df['title'].apply(clean_text)

data_df[['title', 'clean_title']].sample(5)

X = data_df['clean_title']
y = data_df['label']

tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = tfidf.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

print("Train Data Shape:", X_train.shape)
print("Test Data Shape:", X_test.shape)

"""### LOGISTIC REGRESSION"""

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print("Accuracy:", round(accuracy, 4))
print("\nClassification Report:\n", report)
print("Confusion Matrix:\n", conf_matrix)

"""### RANDOM FOREST"""

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

rf_pred = rf_model.predict(X_test)

rf_accuracy = accuracy_score(y_test, rf_pred)
rf_report = classification_report(y_test, rf_pred)
rf_conf_matrix = confusion_matrix(y_test, rf_pred)

print("Random Forest Accuracy:", round(rf_accuracy, 4))
print("\nClassification Report:\n", rf_report)
print("Confusion Matrix:\n", rf_conf_matrix)

"""### XGBOOST"""

!pip install xgboost

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_model.fit(X_train, y_train)

xgb_pred = xgb_model.predict(X_test)

xgb_accuracy = accuracy_score(y_test, xgb_pred)
xgb_report = classification_report(y_test, xgb_pred)
xgb_conf_matrix = confusion_matrix(y_test, xgb_pred)

print("XGBoost Accuracy:", round(xgb_accuracy, 4))
print("\nClassification Report:\n", xgb_report)
print("Confusion Matrix:\n", xgb_conf_matrix)

comparison_data = {
    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],
    'Accuracy': [0.9484, 0.9388, 0.9077],
    'F1-Score': [0.95, 0.94, 0.91],
    'Precision (Fake)': [0.97, 0.94, 0.96],
    'Recall (Real)': [0.96, 0.93, 0.96]
}

comparison_df = pd.DataFrame(comparison_data)

styled_table = comparison_df.style.set_caption("Model Comparison Table") \
    .format("{:.4f}", subset=['Accuracy', 'F1-Score', 'Precision (Fake)', 'Recall (Real)']) \
    .highlight_max(color='lightgreen', axis=0) \
    .set_table_styles([{
        'selector': 'caption',
        'props': [('caption-side', 'top'), ('font-size', '16px'), ('font-weight', 'bold')]
    }])

styled_table

